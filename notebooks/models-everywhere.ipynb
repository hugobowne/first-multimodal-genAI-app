{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your First Multimodal GenAI App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Workshop on Building Composable AI Systems üöÄ\n",
    "\n",
    "In this workshop, we're diving into how to create powerful and flexible AI applications using a code-first approach. The world of AI is evolving rapidly, and we now have access to a multitude of models for generating text, images, audio, and more. But to rell leverage the power of these models, we need to think about **composability**: how we can connect and automate AI capabilities in ways that fit our particular needs.\n",
    "\n",
    "### Why Use Code Interfaces Over Pre-Built Tools?\n",
    "\n",
    "You might wonder, \"Why not just use simple, web-based tools for these tasks?\" The answer lies in the power of customization, automation, and scalability. Let's explore some real-world scenarios:\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 1: Rapid Image Generation for a Marketing Team üé®\n",
    "Imagine you're part of a marketing team launching a new product. You need to generate dozens of image concepts quickly to test different styles and messages. Using a code-based approach, you can:\n",
    "\n",
    "- **Prompt** a language model to come up with creative image descriptions.\n",
    "- **Generate** images from those descriptions using an image model.\n",
    "- **Filter** and select the best images based on specific criteria.\n",
    "- **Send** the top images to your team‚Äôs Slack or email for feedback.\n",
    "\n",
    "This automated workflow saves hours of manual work and ensures your team has more creative options to consider.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 2: Creating Background Music for Content Creators üé∂\n",
    "You're a content creator working on a podcast or video series. Each episode needs custom background music that matches the theme and mood. With this approach, you can:\n",
    "\n",
    "- **Generate** multiple music samples using a generative audio model.\n",
    "- **Adjust** the style, tempo, or instrumentation on the fly.\n",
    "- **Save** and organize the best samples for your project.\n",
    "\n",
    "This allows you to experiment freely and find the perfect sound without having to rely on pre-made music libraries.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 3: Interactive Storytelling or Live Events üé≠\n",
    "Imagine hosting a live event where you want to engage the audience with real-time storytelling. You can build an app that:\n",
    "\n",
    "- **Listens** to audience suggestions through voice input.\n",
    "- **Generates** narrative twists or visual art based on those suggestions.\n",
    "- **Plays** custom soundscapes to match the unfolding story.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 4: Team Collaboration & Idea Generation üí°\n",
    "Consider a product team brainstorming new features for an app. Instead of manually jotting down ideas and creating prototypes, you can build a pipeline that:\n",
    "\n",
    "- **Generates** feature ideas using an LLM.\n",
    "- **Creates** visual prototypes from those ideas using an image model.\n",
    "- **Filters** and prioritizes the best concepts automatically.\n",
    "\n",
    "This speeds up the ideation process and allows your team to explore more possibilities in less time.\n",
    "\n",
    "### Workshop Overview üõ†Ô∏è\n",
    "\n",
    "In this workshop, you will learn how to:\n",
    "- **Compose** AI models to build custom applications.\n",
    "- **Automate** workflows using AI-generated content.\n",
    "- **Experiment** with different models for text, audio, and images.\n",
    "- **Deploy** your own composable AI systems for real-world use cases.\n",
    "\n",
    "We‚Äôll start with a high-level look at composability, inspired by the Unix philosophy: simple, modular components that can be easily combined. Then, we'll get hands-on, building systems that turn your ideas into reality with minimal effort.\n",
    "\n",
    "Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that these types of multimodal aproaches are already available in apps, such as ChatGPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"vid/Dream Advertising Marketing Campaign.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"vid/Dream Advertising Marketing Campaign.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this approach ties you to particular models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore a variety of SOTA GenAI models and get a sense of how to stitch them together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/composability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/karpathy-austen.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"vid/karpathy-austen.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"vid/karpathy-austen.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/unix-phil.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/apple-counterpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/ai-evolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/importance-comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/comp-nec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our API Keys in our environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a [Groq](https://groq.com/) account and navigate [here to get your API key](https://console.groq.com/keys). They have a free tier with a bunch of LLMs (see screenshot below)!\n",
    "- If you'd prefer to use OpenAI, you can do that and get [your API key here](https://platform.openai.com/api-keys).\n",
    "- To use the models below as is, you'll need a [Replicate account](https://replicate.com/). If you're using this notebook in a workshop, chances are Hugo is able to provision free Replicate credits for you so ask him, if he hasn't mentioned it.\n",
    "- Many of these models [you can also find on HuggingFace](https://huggingface.co/models), if you'd prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate API key captured successfully!\n",
      "Groq API key captured successfully!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "\n",
    "# Prompt for the Replicate API key\n",
    "replicate_api_key = getpass.getpass(\"Please enter your Replicate API key: \")\n",
    "print(\"Replicate API key captured successfully!\")\n",
    "\n",
    "# Prompt for the Grok API key\n",
    "groq_api_key = getpass.getpass(\"Please enter your Groq API key: \")\n",
    "print(\"Groq API key captured successfully!\")\n",
    "\n",
    "# # Prompt for the OpenAI API key\n",
    "# openai_api_key = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
    "# print(\"Replicate OpenAI key captured successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suno Bark: text to audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we'll experiment with the [Suno Bark](https://github.com/suno-ai/bark) text to audio model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/3KbzO0kbYqZIBhfRBWRTpMQYjoivQeK3nSIEWbsQWQ0DVStTA/audio.wav', 'prompt_npz': None}\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "# Create a Replicate client instance with the API token\n",
    "client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": \"Hello, my name is Hugo. And, uh ‚Äî and I like pizza. [laughs] But I also have other interests such as playing chess. [chuckles]\",\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\"\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM output --> Suno bark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to pipe the output of an LLM into Bark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def get_llm_response(user_input):\n",
    "    client = Groq(\n",
    "        api_key=groq_api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# from openai import OpenAI\n",
    "# import os\n",
    "\n",
    "\n",
    "# def get_llm_response(user_input):\n",
    "#     client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo-0613\",\n",
    "#         messages=[\n",
    "#     {\"role\": \"user\", \"content\": user_input}\n",
    "#   ]\n",
    "#         )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, gather 'round me hearties, and listen close to me tale,\n",
      "Of a life on the seven seas, where the winds do never fail.\n",
      "\n",
      "(Verse 1)\n",
      "Oh, we set sail on the \"Black Swan's\" back,\n",
      "For the islands of gold and the treasures so vast,\n",
      "Our captain, a swashbuckler, with a heart full of gold,\n",
      "Led us forth to find riches, or a watery cold.\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go,\n",
      "Heave ho, me hearties, the winds do blow,\n",
      "Heave ho, me hearties, let the battle rage,\n",
      "Heave ho, me hearties, and the treasure we'll engage!\n",
      "\n",
      "(Verse 2)\n",
      "The sharks they did circle, the storms did rage,\n",
      "But we held fast to the ship, and our spirits did engage,\n",
      "We fought off the scurvy dogs, and the deadly beast,\n",
      "And reached the shores of victory, and rested our weary feet.\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go,\n",
      "Heave ho, me hearties, the winds do blow,\n",
      "Heave ho, me hearties, let the battle rage,\n",
      "Heave ho, me hearties, and the treasure we'll engage!\n",
      "\n",
      "(Bridge)\n",
      "Oh, the stories we did tell, of the battles we did win,\n",
      "Of the treasures we found, and the mysteries within,\n",
      "The sea was our home, the wind our friend,\n",
      "And we'd sail the seven seas, until the end.\n",
      "\n",
      "(Verse 3)\n",
      "But now the \"Black Swan's\" gone, lost at sea,\n",
      "And I'm the only one left, to tell the tale to thee,\n",
      "So raise your cups, me hearties, to the memories of the past,\n",
      "And may your own tale be told, and may your own treasure forever last.\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go,\n",
      "Heave ho, me hearties, the winds do blow,\n",
      "Heave ho, me hearties, let the battle rage,\n",
      "Heave ho, me hearties, and the treasure we'll engage!\n",
      "\n",
      "Yarrr!\n"
     ]
    }
   ],
   "source": [
    "song = get_llm_response(\"a short pirates sea shanty\")\n",
    "print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/fksIIMEz1egvGkAxK50EvCNt1GPDCWlg1qHoSCZtxG22VStTA/audio.wav', 'prompt_npz': None}\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": song,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is totally bent and makes no sense ‚òùÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music w/ meta musicgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to create some music with text? Let's try Musicgen from Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/5Ps5e37V4PygbyfAL0qIF1RKDKZ59VBQhDxbKWS0T1QqWStTA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Horns and Drums. Edo25 major g melodies that sound triumphant and cinematic. Leading up to a crescendo that resolves in a 9th harmonic\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\"\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/eE35qkwuCw1wekLyNmhR8lipUSeRz9twL60HNseTFurnhJ1OB/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Ancient Trip Hop with Throat Singing\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music with riffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of other models to experiment with, such as riffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': 'https://replicate.delivery/czjl/v8LskkFqSEJbAB8VMhhDVBFjii9scILxczDDiQhZ3LW2mU7E/gen_sound.wav', 'spectrogram': 'https://replicate.delivery/czjl/fLi1Xp3vhgRJUCBtOkBDB8gF5u0QdQMskfoTeLvVf2fObTqdC/spectrogram.jpg'}\n"
     ]
    }
   ],
   "source": [
    "output = client.run(\n",
    "    \"riffusion/riffusion:8cf61ea6c56afd61d8f5b9ffd14d7c216c0a93844ce2d82ac1c9ecc9c7f24e05\",\n",
    "    input={\n",
    "        \"alpha\": 0.5,\n",
    "        \"prompt_a\": \"West African Desert Blues\",\n",
    "        \"prompt_b\": \"Throat Singing\",\n",
    "        \"denoising\": 0.75,\n",
    "        \"seed_image_id\": \"vibes\",\n",
    "        \"num_inference_steps\": 50\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: One prompt to many models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we wanted to use a single prompt to create text, audio, images, and video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"The Waffle House is really messing up the pancakes and bacon tonight HOLY MOLEY and there's anarchist jazz also!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/naSOujsYXDYxDljySnCPHQFb5TIReXmMQzNjCQeP7xwqcStTA/R8__00001_.webp']\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> [\"https://replicate.delivery/pbxt/ulYZRIyAUDYpOZfl7OjhrKx..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/dzYZHYYkWTLmFJvoeXHvjOcInRTWNW2feDSFcPfLlewx7TqdC/audio.wav', 'prompt_npz': None}\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": message,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/O3fhhP3bpBVtPiWwx664x4ggTLukt7IfUDx2f2Il3EcWBlanA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message,\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many models at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some utility functions that use these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epic_realism(prompt, api_token):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"zh_speaker_7\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_music_gen(prompt, api_token, duration=30, model_version=\"stereo-large\", output_format=\"mp3\", normalization_strategy=\"peak\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model_version\": model_version,\n",
    "        \"output_format\": output_format,\n",
    "        \"normalization_strategy\": normalization_strategy,\n",
    "        \"duration\": duration \n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"announcer\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/JHwgByESzW6FCpaQWnpfaEYXBE7PJy6IiWpFeUnpsJD6hStTA/R8__00001_.webp']\n",
      "{'audio_out': 'https://replicate.delivery/czjl/PLHLseg6EhT4YCOtKeF7zj6we9a2GeVeLcJsqPQ9ul55DVqdC/audio.wav', 'prompt_npz': None}\n",
      "https://replicate.delivery/yhqm/XtxMwbfHk4XbHqG7ftIlpH1fRBKmKggTofMbRtnlLy7VmK1OB/out.mp3\n"
     ]
    }
   ],
   "source": [
    "message = \"crazy wild zombie party at the blaring symphony orchestra\"\n",
    "output = generate_epic_realism(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_suno_bark(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_music_gen(message, replicate_api_key)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epic Realism Output:\n",
      "['https://replicate.delivery/pbxt/GHKFnGfyRsWYACcHgg22HP6hJUDrhFdNRxkKtxLamUnzUp2JA/R8__00001_.webp']\n",
      "Meta MusicGen Output:\n",
      "https://replicate.delivery/yhqm/xo81Ixf8hv0bL69f47Q4y2cWtrjHPMGv71lMGRp6kFsarStTA/out.mp3\n",
      "Suno Bark Output:\n",
      "{'audio_out': 'https://replicate.delivery/czjl/egt08ZFPeEkj30twSbgpgaElvagjxkA51VoSeY5YY1KqXlanA/audio.wav', 'prompt_npz': None}\n"
     ]
    }
   ],
   "source": [
    "# Define your API token and prompt message\n",
    "# api_token = 'your_api_token_here'\n",
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "# Run the Epic Realism model\n",
    "epicrealism_output = generate_epic_realism(message, replicate_api_key)\n",
    "print(\"Epic Realism Output:\")\n",
    "print(epicrealism_output)\n",
    "\n",
    "# Run the Meta MusicGen model\n",
    "musicgen_output = generate_music_gen(message, replicate_api_key)\n",
    "print(\"Meta MusicGen Output:\")\n",
    "print(musicgen_output)\n",
    "\n",
    "# Run the Suno Bark model\n",
    "bark_output = generate_suno_bark(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: text to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/iBXTe8egVzgBDknYEVHncIhUjp1uqrqm8OfV7d1aorHZeK1OB/out.mp4\n"
     ]
    }
   ],
   "source": [
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "input = {\n",
    "    \"sampler\": \"klms\",\n",
    "    \"max_frames\": 100,\n",
    "    \"animation_prompts\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"deforum/deforum_stable_diffusion:e22e77495f2fb83c34d5fae2ad8ab63c0a87b6b573b6208e1535b23b89ea66d6\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/mgxm/873a1cc7-0427-4e8d-ab3c-..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments-in-ai-UifnU4Ym-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
