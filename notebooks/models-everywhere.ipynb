{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your First Multimodal GenAI App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore a variety of SOTA GenAI models and get a sense of how to stitch them together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our API Keys in our environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a [Groq](https://groq.com/) account and navigate [here to get your API key](https://console.groq.com/keys). They have a free tier with a bunch of LLMs (see screenshot below)!\n",
    "- If you'd prefer to use OpenAI, you can do that and get [your API key here](https://platform.openai.com/api-keys).\n",
    "- To use the models below as is, you'll need a [Replicate account](https://replicate.com/). If you're using this notebook in a workshop, chances are Hugo is able to provision free Replicate credits for you so ask him, if he hasn't mentioned it. If you're at ODSC APAC (August, 2024), complete [this form](https://forms.gle/AcaY1dki6Gxpgd4y7) and Hugo will send you credits (expire Aug 20)\n",
    "- Many of these models [you can also find on HuggingFace](https://huggingface.co/models), if you'd prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate API key captured successfully!\n",
      "Groq API key captured successfully!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "\n",
    "# Prompt for the Replicate API key\n",
    "replicate_api_key = getpass.getpass(\"Please enter your Replicate API key: \")\n",
    "print(\"Replicate API key captured successfully!\")\n",
    "\n",
    "# Prompt for the Grok API key\n",
    "groq_api_key = getpass.getpass(\"Please enter your Groq API key: \")\n",
    "print(\"Groq API key captured successfully!\")\n",
    "\n",
    "# # Prompt for the OpenAI API key\n",
    "# openai_api_key = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
    "# print(\"Replicate OpenAI key captured successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suno Bark: text to audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we'll experiment with the [Suno Bark](https://github.com/suno-ai/bark) text to audio model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/swKgub3nE0IALZpzMypqGmBfH3GZDl983qIi07fzwj4aKHSTA/audio.wav'}\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "# Create a Replicate client instance with the API token\n",
    "client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": \"Hello, my name is Hugo. And, uh — and I like pizza. [laughs] But I also have other interests such as playing chess. [chuckles]\",\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\"\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM output --> Suno bark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to pipe the output of an LLM into Bark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def get_llm_response(user_input):\n",
    "    client = Groq(\n",
    "        api_key=groq_api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# from openai import OpenAI\n",
    "# import os\n",
    "\n",
    "\n",
    "# def get_llm_response(user_input):\n",
    "#     client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo-0613\",\n",
    "#         messages=[\n",
    "#     {\"role\": \"user\", \"content\": user_input}\n",
    "#   ]\n",
    "#         )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, here's a short pirate sea shanty for ye:\n",
      "\n",
      "(Verse 1)\n",
      "Oh, we set sail on the Black Swan's tide\n",
      "Bound for Spain, where the treasure's hide\n",
      "Our crew's as salty as the sea we sail\n",
      "We'll plunder and pillage, without fail\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go\n",
      "In the Caribbean, we'll find our gold, yo\n",
      "Heave ho, me hearties, the winds they do blow\n",
      "We'll sing and we'll fight, until our victory show\n",
      "\n",
      "(Verse 2)\n",
      "Our captain's beard is long and gray\n",
      "He's fought in battles, night and day\n",
      "Our bosun's got a hook for a hand\n",
      "He'll make ye walk the plank, if ye don't stand\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go\n",
      "In the Caribbean, we'll find our gold, yo\n",
      "Heave ho, me hearties, the winds they do blow\n",
      "We'll sing and we'll fight, until our victory show\n",
      "\n",
      "(Bridge)\n",
      "So raise yer tankards, me hearties all\n",
      "And toast to the sea, and the courage we'll call\n",
      "For we be pirates, bold and true\n",
      "And our legend will live, forever anew\n",
      "\n",
      "(Chorus)\n",
      "Heave ho, me hearties, let the anchor go\n",
      "In the Caribbean, we'll find our gold, yo\n",
      "Heave ho, me hearties, the winds they do blow\n",
      "We'll sing and we'll fight, until our victory show\n"
     ]
    }
   ],
   "source": [
    "song = get_llm_response(\"a short pirates sea shanty\")\n",
    "print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/GTHvkAE45ELrIl2But8AJwTveBpeejReSLDXJpUB6gY3scINB/audio.wav'}\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": song,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is totally bent and makes no sense ☝️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music w/ meta musicgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to create some music with text? Let's try Musicgen from Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/ToWKm0N4lUqFLh8N8nh9k4fhzyz8veKeHe0Lkrf2wxlFc5QaC/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Horns and Drums. Edo25 major g melodies that sound triumphant and cinematic. Leading up to a crescendo that resolves in a 9th harmonic\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\"\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/f3gL4sACCDx5RaFu8MF5wsnhz8vqWROjfTcBw5PscPBqMHSTA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Ancient Trip Hop with Throat Singing\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music with riffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of other models to experiment with, such as riffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': 'https://replicate.delivery/czjl/G2OwfkftGzomoETExQylu2tXMFvmPWtMqfbYYJ47BPvnZOkmA/gen_sound.wav', 'spectrogram': 'https://replicate.delivery/czjl/pOiQNgILoHZ4G9e40ejnBefju9W3RBbBHvSIWdBT4BcMzcINB/spectrogram.jpg'}\n"
     ]
    }
   ],
   "source": [
    "output = client.run(\n",
    "    \"riffusion/riffusion:8cf61ea6c56afd61d8f5b9ffd14d7c216c0a93844ce2d82ac1c9ecc9c7f24e05\",\n",
    "    input={\n",
    "        \"alpha\": 0.5,\n",
    "        \"prompt_a\": \"West African Desert Blues\",\n",
    "        \"prompt_b\": \"Throat Singing\",\n",
    "        \"denoising\": 0.75,\n",
    "        \"seed_image_id\": \"vibes\",\n",
    "        \"num_inference_steps\": 50\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: One prompt to many models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we wanted to use a single prompt to create text, audio, images, and video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"The Waffle House is really messing up the pancakes and bacon tonight HOLY MOLEY and there's anarchist jazz also!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/2C3d46eff6ITXIJf3QCf0KteMMFiYUmtdzAefNc9zC4V1MHSTA/R8__00001_.webp']\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> [\"https://replicate.delivery/pbxt/ulYZRIyAUDYpOZfl7OjhrKx..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_out': 'https://replicate.delivery/czjl/bUffZN42SoioX0S9lVV9s4hKH3fL6sx4w1Dge1qGYvtk1cINB/audio.wav'}\n"
     ]
    }
   ],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": message,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/Du1yhfPBxM3XLS17tbC7x7yyOe2rOfsRZRsgGOR0bb7e5cINB/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message,\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many models at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some utility functions that use these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epic_realism(prompt, api_token):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"zh_speaker_7\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_music_gen(prompt, api_token, duration=30, model_version=\"stereo-large\", output_format=\"mp3\", normalization_strategy=\"peak\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model_version\": model_version,\n",
    "        \"output_format\": output_format,\n",
    "        \"normalization_strategy\": normalization_strategy,\n",
    "        \"duration\": duration \n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"announcer\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/qhe4MITqZGylCyKPeY8LHa86I6ep31HXV7AQh5z9oEPEdOkmA/R8__00001_.webp']\n",
      "{'audio_out': 'https://replicate.delivery/czjl/u0QcO80BT9quEloJYuXzCKLTUaNloq9qrLpm4WP7fplanDpJA/audio.wav'}\n",
      "https://replicate.delivery/yhqm/0Jyd5dzh5qJWMZfx8GMnsDkrKwoy95zo9abqp4oSoedcQHSTA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "message = \"crazy wild zombie party at the blaring symphony orchestra\"\n",
    "output = generate_epic_realism(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_suno_bark(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_music_gen(message, replicate_api_key)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epic Realism Output:\n",
      "['https://replicate.delivery/pbxt/ap5vInR47d7VAhnVO3gzhPv3ltKwZNueDufEUBAxyLFegOkmA/R8__00001_.webp']\n",
      "Meta MusicGen Output:\n",
      "https://replicate.delivery/yhqm/RQYRBFXtyRr7ChSfn2rpkDwZrBwMgZVE9LyX48YXkF6zoDpJA/out.mp3\n",
      "Suno Bark Output:\n",
      "{'audio_out': 'https://replicate.delivery/czjl/X4tGcQZIn0rjENB0hDFr5nSlzorIcHRem5xzjdGfeXx7jOkmA/audio.wav'}\n"
     ]
    }
   ],
   "source": [
    "# Define your API token and prompt message\n",
    "# api_token = 'your_api_token_here'\n",
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "# Run the Epic Realism model\n",
    "epicrealism_output = generate_epic_realism(message, replicate_api_key)\n",
    "print(\"Epic Realism Output:\")\n",
    "print(epicrealism_output)\n",
    "\n",
    "# Run the Meta MusicGen model\n",
    "musicgen_output = generate_music_gen(message, replicate_api_key)\n",
    "print(\"Meta MusicGen Output:\")\n",
    "print(musicgen_output)\n",
    "\n",
    "# Run the Suno Bark model\n",
    "bark_output = generate_suno_bark(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: text to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/ghKmg6PI2s7fBS1mkWwJe1a9jD5V1MpisDZ0hGB2sX12UHSTA/out.mp4\n"
     ]
    }
   ],
   "source": [
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "input = {\n",
    "    \"sampler\": \"klms\",\n",
    "    \"max_frames\": 100,\n",
    "    \"animation_prompts\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"deforum/deforum_stable_diffusion:e22e77495f2fb83c34d5fae2ad8ab63c0a87b6b573b6208e1535b23b89ea66d6\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/mgxm/873a1cc7-0427-4e8d-ab3c-..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments-in-ai-MDGx_Oj2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
