{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your First Multimodal GenAI App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Workshop on Building Composable AI Systems üöÄ\n",
    "\n",
    "In this workshop, we're diving into how to create powerful and flexible AI applications using a code-first approach. The world of AI is evolving rapidly, and we now have access to a multitude of models for generating text, images, audio, and more. But to rell leverage the power of these models, we need to think about **composability**: how we can connect and automate AI capabilities in ways that fit our particular needs.\n",
    "\n",
    "### Why Use Code Interfaces Over Pre-Built Tools?\n",
    "\n",
    "You might wonder, \"Why not just use simple, web-based tools for these tasks?\" The answer lies in the power of customization, automation, and scalability. Let's explore some real-world scenarios:\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 1: Rapid Image Generation for a Marketing Team üé®\n",
    "Imagine you're part of a marketing team launching a new product. You need to generate dozens of image concepts quickly to test different styles and messages. Using a code-based approach, you can:\n",
    "\n",
    "- **Prompt** a language model to come up with creative image descriptions.\n",
    "- **Generate** images from those descriptions using an image model.\n",
    "- **Filter** and select the best images based on specific criteria.\n",
    "- **Send** the top images to your team‚Äôs Slack or email for feedback.\n",
    "\n",
    "This automated workflow saves hours of manual work and ensures your team has more creative options to consider.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 2: Creating Background Music for Content Creators üé∂\n",
    "You're a content creator working on a podcast or video series. Each episode needs custom background music that matches the theme and mood. With this approach, you can:\n",
    "\n",
    "- **Generate** multiple music samples using a generative audio model.\n",
    "- **Adjust** the style, tempo, or instrumentation on the fly.\n",
    "- **Save** and organize the best samples for your project.\n",
    "\n",
    "This allows you to experiment freely and find the perfect sound without having to rely on pre-made music libraries.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 3: Interactive Storytelling or Live Events üé≠\n",
    "Imagine hosting a live event where you want to engage the audience with real-time storytelling. You can build an app that:\n",
    "\n",
    "- **Listens** to audience suggestions through voice input.\n",
    "- **Generates** narrative twists or visual art based on those suggestions.\n",
    "- **Plays** custom soundscapes to match the unfolding story.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 4: Team Collaboration & Idea Generation üí°\n",
    "Consider a product team brainstorming new features for an app. Instead of manually jotting down ideas and creating prototypes, you can build a pipeline that:\n",
    "\n",
    "- **Generates** feature ideas using an LLM.\n",
    "- **Creates** visual prototypes from those ideas using an image model.\n",
    "- **Filters** and prioritizes the best concepts automatically.\n",
    "\n",
    "This speeds up the ideation process and allows your team to explore more possibilities in less time.\n",
    "\n",
    "### Workshop Overview üõ†Ô∏è\n",
    "\n",
    "In this workshop, you will learn how to:\n",
    "- **Compose** AI models to build custom applications.\n",
    "- **Automate** workflows using AI-generated content.\n",
    "- **Experiment** with different models for text, audio, and images.\n",
    "- **Deploy** your own composable AI systems for real-world use cases.\n",
    "\n",
    "We‚Äôll start with a high-level look at composability, inspired by the Unix philosophy: simple, modular components that can be easily combined. Then, we'll get hands-on, building systems that turn your ideas into reality with minimal effort.\n",
    "\n",
    "Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that these types of multimodal aproaches are already available in apps, such as ChatGPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"vid/Dream Advertising Marketing Campaign.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"vid/Dream Advertising Marketing Campaign.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this approach ties you to particular models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore a variety of SOTA GenAI models and get a sense of how to stitch them together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/composability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/karpathy-austen.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"vid/karpathy-austen.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"vid/karpathy-austen.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/unix-phil.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/apple-counterpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/ai-evolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/importance-comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/comp-nec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our API Keys in our environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a [Groq](https://groq.com/) account and navigate [here to get your API key](https://console.groq.com/keys). They have a free tier with a bunch of LLMs (see screenshot below)!\n",
    "- If you'd prefer to use OpenAI, you can do that and get [your API key here](https://platform.openai.com/api-keys).\n",
    "- To use the models below as is, you'll need a [Replicate account](https://replicate.com/). If you're using this notebook in a workshop, chances are Hugo is able to provision free Replicate credits for you so ask him, if he hasn't mentioned it.\n",
    "- Many of these models [you can also find on HuggingFace](https://huggingface.co/models), if you'd prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate API key captured successfully!\n",
      "Groq API key captured successfully!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "\n",
    "# Prompt for the Replicate API key\n",
    "replicate_api_key = getpass.getpass(\"Please enter your Replicate API key: \")\n",
    "print(\"Replicate API key captured successfully!\")\n",
    "\n",
    "# Prompt for the Grok API key\n",
    "groq_api_key = getpass.getpass(\"Please enter your Groq API key: \")\n",
    "print(\"Groq API key captured successfully!\")\n",
    "\n",
    "# # Prompt for the OpenAI API key\n",
    "# openai_api_key = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
    "# print(\"Replicate OpenAI key captured successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suno Bark: text to audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we'll experiment with the [Suno Bark](https://github.com/suno-ai/bark) text to audio model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/wybNlPef3IvDRE4hiChxvdVS0n7snQZo55gs4bfdoXjyg6bnA/output.wav\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "# Create a Replicate client instance with the API token\n",
    "client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "output = client.run(\n",
    "    \"x-lance/f5-tts:87faf6dd7a692dd82043f662e76369cab126a2cf1937e25a9d41e0b834fd230e\",\n",
    "    input={\n",
    "        \"gen_text\": \"captain hugo, on duty!\",\n",
    "        \"ref_text\": \"never underestimate the power of the scout's code\",\n",
    "        \"ref_audio\": \"https://replicate.delivery/pbxt/LnHEJTVWhjLcpGQJTBralyztLwl8diaLyHjP2a1KXJ8dxVWv/Teemo_Original_Taunt.ogg\",\n",
    "        \"remove_silence\": True,\n",
    "        \"custom_split_words\": \"\"\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM output --> Suno bark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to pipe the output of an LLM into Bark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def get_llm_response(user_input):\n",
    "    client = Groq(\n",
    "        api_key=groq_api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# from openai import OpenAI\n",
    "# import os\n",
    "\n",
    "\n",
    "# def get_llm_response(user_input):\n",
    "#     client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-3.5-turbo-0613\",\n",
    "#         messages=[\n",
    "#     {\"role\": \"user\", \"content\": user_input}\n",
    "#   ]\n",
    "#         )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short pirate sea shanty:\n",
      "\n",
      "(sung to the tune of \"What Shall We Do with a Drunken Sailor\")\n",
      "\n",
      "Oh, the captain stands on the quarterdeck high\n",
      "With his trusty compass and an eye on the sky\n",
      "He's searchin' for treasure, plunder and gold\n",
      "And a crew to sing along as we sail to old\n",
      "\n",
      "We'll hoist the Jolly Roger, let it wave in the breeze\n",
      "And sing and shout and drink our grog with ease\n",
      "We'll dance on the deck and play our sea shanty tune\n",
      "For we're pirates bold, on the ocean we've been known\n",
      "\n",
      "Oh, we'll ride the waves and sing as we go\n",
      "On our journey to the Caribbean from the Bosphorus, you know\n",
      "We'll drink and we'll jest and we'll tell our yarns\n",
      "For we're pirates, and the sea is our home, and we swear no barns!\n",
      "\n",
      "Yarrr!\n"
     ]
    }
   ],
   "source": [
    "song = get_llm_response(\"a short pirates sea shanty\")\n",
    "print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/vx3JskrK62KeDaDSbD3fgCuv04yMDS4XNq0j8fcvA3Slh6bnA/output.wav\n"
     ]
    }
   ],
   "source": [
    "output = client.run(\n",
    "    \"x-lance/f5-tts:87faf6dd7a692dd82043f662e76369cab126a2cf1937e25a9d41e0b834fd230e\",\n",
    "    input={\n",
    "        \"gen_text\": song,\n",
    "        \"ref_text\": \"never underestimate the power of the scout's code\",\n",
    "        \"ref_audio\": \"https://replicate.delivery/pbxt/LnHEJTVWhjLcpGQJTBralyztLwl8diaLyHjP2a1KXJ8dxVWv/Teemo_Original_Taunt.ogg\",\n",
    "        \"remove_silence\": True,\n",
    "        \"custom_split_words\": \"\"\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music w/ meta musicgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to create some music with text? Let's try Musicgen from Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/MBBfVjxfEgjgc0yXBDICx5xDQIZaD8jI2OHfS5qG0u2zi6bnA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Horns and Drums. Edo25 major g melodies that sound triumphant and cinematic. Leading up to a crescendo that resolves in a 9th harmonic\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\"\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/xvXTf1MqtMTXUCmJKeECFHhgjaYqp6svezbHf0bCfon9TqvdC/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Ancient Trip Hop with Throat Singing\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music with riffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of other models to experiment with, such as riffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': 'https://replicate.delivery/czjl/KJn0JSKssfyflUaYNfHveLeeVEXwYQJc1edZGntKNhfeXl6bnA/gen_sound.wav', 'spectrogram': 'https://replicate.delivery/czjl/ykuCE1ZPVRL3JtnwGf3MoBW5e461pAvhDfh1uWUDEt3Xl6bnA/spectrogram.jpg'}\n"
     ]
    }
   ],
   "source": [
    "output = client.run(\n",
    "    \"riffusion/riffusion:8cf61ea6c56afd61d8f5b9ffd14d7c216c0a93844ce2d82ac1c9ecc9c7f24e05\",\n",
    "    input={\n",
    "        \"alpha\": 0.5,\n",
    "        \"prompt_a\": \"West African Desert Blues\",\n",
    "        \"prompt_b\": \"Throat Singing\",\n",
    "        \"denoising\": 0.75,\n",
    "        \"seed_image_id\": \"vibes\",\n",
    "        \"num_inference_steps\": 50\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: One prompt to many models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we wanted to use a single prompt to create text, audio, images, and video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"The Waffle House is really messing up the pancakes and bacon tonight HOLY MOLEY and there's anarchist jazz also!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/LfupBRuofqjyp08abH0BgfbeJIWdqI323XqVyc8WUmxiN13OB/R8__00001_.webp']\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> [\"https://replicate.delivery/pbxt/ulYZRIyAUDYpOZfl7OjhrKx..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Waffle House is really messing up the pancakes and bacon tonight HOLY MOLEY and there's anarchist jazz also!\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/MOCU8DxsSmqzHZzoVffRremzP4Fnabl75tHc4nkcuUS0o6bnA/output.wav\n"
     ]
    }
   ],
   "source": [
    "output = client.run(\n",
    "    \"x-lance/f5-tts:87faf6dd7a692dd82043f662e76369cab126a2cf1937e25a9d41e0b834fd230e\",\n",
    "    input={\n",
    "        \"gen_text\": message,\n",
    "        \"ref_text\": \"never underestimate the power of the scout's code\",\n",
    "        \"ref_audio\": \"https://replicate.delivery/pbxt/LnHEJTVWhjLcpGQJTBralyztLwl8diaLyHjP2a1KXJ8dxVWv/Teemo_Original_Taunt.ogg\",\n",
    "        \"remove_silence\": True,\n",
    "        \"custom_split_words\": \"\"\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/fKPRqJ13XEy3PaiemzVftJhavz5bydhOLjvMjQzoHvrCr6bnA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"prompt\": message,\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many models at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some utility functions that use these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epic_realism(prompt, api_token):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "#     # Create a Replicate client instance with the API token\n",
    "#     client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "#     # Define the input parameters for the model\n",
    "#     input_params = {\n",
    "#         \"prompt\": prompt,\n",
    "#         \"text_temp\": text_temp,\n",
    "#         \"output_full\": output_full,\n",
    "#         \"waveform_temp\": waveform_temp,\n",
    "#         \"history_prompt\": \"zh_speaker_7\",\n",
    "#     }\n",
    "\n",
    "#     # Run the model using Replicate API\n",
    "#     try:\n",
    "#         output = client.run(\n",
    "#             \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "#             input=input_params\n",
    "#         )\n",
    "#         return output\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_music_gen(prompt, api_token, duration=30, model_version=\"stereo-large\", output_format=\"mp3\", normalization_strategy=\"peak\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model_version\": model_version,\n",
    "        \"output_format\": output_format,\n",
    "        \"normalization_strategy\": normalization_strategy,\n",
    "        \"duration\": duration \n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"announcer\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_f5(prompt, api_token):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "    output = client.run(\n",
    "        \"x-lance/f5-tts:87faf6dd7a692dd82043f662e76369cab126a2cf1937e25a9d41e0b834fd230e\",\n",
    "        input={\n",
    "            \"gen_text\": prompt,\n",
    "            \"ref_text\": \"never underestimate the power of the scout's code\",\n",
    "            \"ref_audio\": \"https://replicate.delivery/pbxt/LnHEJTVWhjLcpGQJTBralyztLwl8diaLyHjP2a1KXJ8dxVWv/Teemo_Original_Taunt.ogg\",\n",
    "            \"remove_silence\": True,\n",
    "            \"custom_split_words\": \"\"\n",
    "        }\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://replicate.delivery/pbxt/iPF40CjW9CIvNBhKCzO6uyfcU3HjjyDenf6d2iTWen4Jb13OB/R8__00001_.webp']\n",
      "https://replicate.delivery/yhqm/DeYnpvdxtkWpZ6xNIfXzfesg5WWJbiqviFS3HgOomKuzi13OB/output.wav\n",
      "https://replicate.delivery/yhqm/2QbO5lBMp3LlE1d3hBuF9EIYf4ETGW43EDI3i2wLg955setTA/out.mp3\n"
     ]
    }
   ],
   "source": [
    "message = \"crazy wild zombie party at the blaring symphony orchestra\"\n",
    "output = generate_epic_realism(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_f5(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "output = generate_music_gen(message, replicate_api_key)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epic Realism Output:\n",
      "['https://replicate.delivery/pbxt/i04ppXTefyl3m05U5nizQkY8L1qE0wc3JIe5OyOTDztu26bnA/R8__00001_.webp']\n",
      "Meta MusicGen Output:\n",
      "https://replicate.delivery/yhqm/jOIw2FwqmDIROFcBsPgjKTiovMCeWXWUNCS975lG6MDUuetTA/out.mp3\n",
      "Suno Bark Output:\n",
      "https://replicate.delivery/yhqm/0s8HPb8LgmImGtIubO1qtlG5UVchfi0SHa7lAeiweE4X76bnA/output.wav\n"
     ]
    }
   ],
   "source": [
    "# Define your API token and prompt message\n",
    "# api_token = 'your_api_token_here'\n",
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "# Run the Epic Realism model\n",
    "epicrealism_output = generate_epic_realism(message, replicate_api_key)\n",
    "print(\"Epic Realism Output:\")\n",
    "print(epicrealism_output)\n",
    "\n",
    "# Run the Meta MusicGen model\n",
    "musicgen_output = generate_music_gen(message, replicate_api_key)\n",
    "print(\"Meta MusicGen Output:\")\n",
    "print(musicgen_output)\n",
    "\n",
    "# Run the Suno Bark model\n",
    "bark_output = generate_f5(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: text to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/hOb98yie1egiX0nrtfm7pRIxjHGOKFDAtNykfdExfse6HYf2JA/out.mp4\n"
     ]
    }
   ],
   "source": [
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "input = {\n",
    "    \"sampler\": \"klms\",\n",
    "    \"max_frames\": 100,\n",
    "    \"animation_prompts\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"deforum/deforum_stable_diffusion:e22e77495f2fb83c34d5fae2ad8ab63c0a87b6b573b6208e1535b23b89ea66d6\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/mgxm/873a1cc7-0427-4e8d-ab3c-..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/today.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/explore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/models.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://replicate.delivery/yhqm/l21N0GeER0z3KqcMwfxznap2QKF0oBD3mjVzLxIgDUUjh9tTA/output.wav\n"
     ]
    }
   ],
   "source": [
    "# Create a Replicate client instance with the API token\n",
    "client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "output = client.run(\n",
    "    \"x-lance/f5-tts:87faf6dd7a692dd82043f662e76369cab126a2cf1937e25a9d41e0b834fd230e\",\n",
    "    input={\n",
    "        \"gen_text\": \"captain hugo, on duty!\",\n",
    "        \"ref_text\": \"never underestimate the power of the scout's code\",\n",
    "        \"ref_audio\": \"https://replicate.delivery/pbxt/LnHEJTVWhjLcpGQJTBralyztLwl8diaLyHjP2a1KXJ8dxVWv/Teemo_Original_Taunt.ogg\",\n",
    "        \"remove_silence\": True,\n",
    "        \"custom_split_words\": \"\"\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments-in-ai-UifnU4Ym-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
