{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your First Multimodal GenAI App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](img/multimodal_app_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore a variety of SOTA GenAI models and get a sense of how to stitch them together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get our API Keys in our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate API key captured successfully!\n",
      "Groq API key captured successfully!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "# Prompt for the OpenAI API key\n",
    "openai_api_key = getpass.getpass(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "# Prompt for the Replicate API key\n",
    "replicate_api_key = getpass.getpass(\"Please enter your Replicate API key: \")\n",
    "print(\"Replicate API key captured successfully!\")\n",
    "\n",
    "# Prompt for the Grok API key\n",
    "groq_api_key = getpass.getpass(\"Please enter your Groq API key: \")\n",
    "print(\"Groq API key captured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suno Bark: text to audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we'll experiment with the [Suno Bark](https://github.com/suno-ai/bark) text to audio model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "# Create a Replicate client instance with the API token\n",
    "client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": \"Hello, my name is Hugo. And, uh â€” and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\",\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\"\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM output --> Suno bark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to pipe the output of an LLM into Bark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "def get_llm_response(user_input):\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "    {\"role\": \"user\", \"content\": user_input}\n",
    "  ]\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = get_llm_response(\"a short pirates sea shanty\")\n",
    "print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": song,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is totally bent and makes no sense lolz ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music w/ meta musicgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Horns and Drums. Edo25 major g melodies that sound triumphant and cinematic. Leading up to a crescendo that resolves in a 9th harmonic\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\"\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"prompt\": \"Ancient Trip Hop with Throat Singing\",\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to music with riffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = client.run(\n",
    "    \"riffusion/riffusion:8cf61ea6c56afd61d8f5b9ffd14d7c216c0a93844ce2d82ac1c9ecc9c7f24e05\",\n",
    "    input={\n",
    "        \"alpha\": 0.5,\n",
    "        \"prompt_a\": \"West African Desert Blues\",\n",
    "        \"prompt_b\": \"Throat Singing\",\n",
    "        \"denoising\": 0.75,\n",
    "        \"seed_image_id\": \"vibes\",\n",
    "        \"num_inference_steps\": 50\n",
    "    }\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: One prompt to many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"The Waffle House is really messing shit up with pancakes and bacon tonight HOLY MOLEY and there's anarchist jazz also!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"prompt\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> [\"https://replicate.delivery/pbxt/ulYZRIyAUDYpOZfl7OjhrKx..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input parameters for the model\n",
    "input_params = {\n",
    "    \"prompt\": message,\n",
    "    \"text_temp\": 0.7,\n",
    "    \"output_full\": False,\n",
    "    \"waveform_temp\": 0.7,\n",
    "    \"history_prompt\": \"announcer\",\n",
    "   # \"duration\": 30\n",
    "}\n",
    "\n",
    "# Run the model using Replicate API\n",
    "try:\n",
    "    output = client.run(\n",
    "        \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "        input=input_params\n",
    "    )\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text to music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"prompt\": message,\n",
    "    \"model_version\": \"stereo-large\",\n",
    "    \"output_format\": \"mp3\",\n",
    "    \"normalization_strategy\": \"peak\",\n",
    "    \"duration\": 30 \n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/pbxt/OeLYIQiltdzMaCex1shlEFy6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many models at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "def generate_epic_realism(prompt, api_token):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"fofr/epicrealismxl-lightning-hades:0ca10b1fd361c1c5568720736411eaa89d9684415eb61fd36875b4d3c20f605a\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "# api_token = XXX\n",
    "message = \"crazy wild zombie party at the blaring symphony orchestra\"\n",
    "output = generate_epic_realism(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "\n",
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"zh_speaker_7\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# api_token = 'your_api_token_here'\n",
    "# message = \"Your prompt here\"\n",
    "output = generate_suno_bark(message, replicate_api_key)\n",
    "print(output)\n",
    "\n",
    "import replicate\n",
    "\n",
    "def generate_music_gen(prompt, api_token, duration=30, model_version=\"stereo-large\", output_format=\"mp3\", normalization_strategy=\"peak\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model_version\": model_version,\n",
    "        \"output_format\": output_format,\n",
    "        \"normalization_strategy\": normalization_strategy,\n",
    "        \"duration\": duration \n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    output = client.run(\n",
    "        \"meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb\",\n",
    "        input=input_data\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "# api_token = 'your_api_token_here'\n",
    "# message = \"Ancient Trip Hop with Throat Singing\"\n",
    "output = generate_music_gen(message, replicate_api_key)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suno_bark(prompt, api_token, text_temp=0.7, output_full=False, waveform_temp=0.7, history_prompt=\"announcer\"):\n",
    "    # Create a Replicate client instance with the API token\n",
    "    client = replicate.Client(api_token=replicate_api_key)\n",
    "\n",
    "    # Define the input parameters for the model\n",
    "    input_params = {\n",
    "        \"prompt\": prompt,\n",
    "        \"text_temp\": text_temp,\n",
    "        \"output_full\": output_full,\n",
    "        \"waveform_temp\": waveform_temp,\n",
    "        \"history_prompt\": \"announcer\",\n",
    "    }\n",
    "\n",
    "    # Run the model using Replicate API\n",
    "    try:\n",
    "        output = client.run(\n",
    "            \"suno-ai/bark:b76242b40d67c76ab6742e987628a2a9ac019e11d56ab96c4e91ce03b79b2787\",\n",
    "            input=input_params\n",
    "        )\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# api_token = 'your_api_token_here'\n",
    "# message = \"Your prompt here\"\n",
    "output = generate_suno_bark(message, replicate_api_key)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API token and prompt message\n",
    "# api_token = 'your_api_token_here'\n",
    "message = \"The Waffle House messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "# Run the Epic Realism model\n",
    "epicrealism_output = generate_epic_realism(message, replicate_api_key)\n",
    "print(\"Epic Realism Output:\")\n",
    "print(epicrealism_output)\n",
    "\n",
    "# Run the Meta MusicGen model\n",
    "musicgen_output = generate_music_gen(message, replicate_api_key)\n",
    "print(\"Meta MusicGen Output:\")\n",
    "print(musicgen_output)\n",
    "\n",
    "# Run the Suno Bark model\n",
    "bark_output = generate_suno_bark(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now define a little LLM utility function to help us out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(user_input):\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "    {\"role\": \"user\", \"content\": user_input}\n",
    "  ]\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = get_llm_response(\"short pirates sea shanty about mermaids\")\n",
    "print(message)\n",
    "# Run the Suno Bark model\n",
    "bark_output = generate_suno_bark(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: text to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "message = \"The Double RR diner messing it up for real with the pancakes and bacon and punk abstract jazz, yo!\"\n",
    "\n",
    "input = {\n",
    "    \"sampler\": \"klms\",\n",
    "    \"max_frames\": 100,\n",
    "    \"animation_prompts\": message\n",
    "}\n",
    "\n",
    "output = client.run(\n",
    "    \"deforum/deforum_stable_diffusion:e22e77495f2fb83c34d5fae2ad8ab63c0a87b6b573b6208e1535b23b89ea66d6\",\n",
    "    input=input\n",
    ")\n",
    "print(output)\n",
    "#=> \"https://replicate.delivery/mgxm/873a1cc7-0427-4e8d-ab3c-..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"giddy up!!! [laughs] time for the thunderdome! [thunder]\"\n",
    "\n",
    "bark_output = generate_suno_bark(message, replicate_api_key)\n",
    "print(\"Suno Bark Output:\")\n",
    "print(bark_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"which model are you\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments-in-ai-MDGx_Oj2-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
